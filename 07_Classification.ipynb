{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "028e526d-3b85-44e0-9b9c-289ff78ba3ac",
   "metadata": {},
   "source": [
    "# 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f6e269-aba3-4c24-a155-4c8308f9ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,        # 범주형 → 수치형 인코딩\n",
    "    OneHotEncoder,        # 원-핫 인코딩\n",
    "    VectorAssembler,      # 여러 컬럼 → 하나의 feature 벡터\n",
    "    StandardScaler,       # 표준 정규화\n",
    "    MinMaxScaler,         # 최소/최대 스케일링\n",
    "    Bucketizer,           # 연속형 변수 → 구간화\n",
    "    QuantileDiscretizer,  # 분위수 기반 구간화\n",
    "    PCA,                  # 주성분 분석\n",
    "    PolynomialExpansion,  # 다항 특성 생성\n",
    "    ChiSqSelector         # 카이제곱 기반 피처 선택\n",
    ")\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier,\n",
    "    NaiveBayes,\n",
    "    MultilayerPerceptronClassifier\n",
    ")\n",
    "\n",
    "from pyspark.ml.regression import (\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor\n",
    ")\n",
    "from pyspark.ml.clustering import (\n",
    "    KMeans,\n",
    "    GaussianMixture,\n",
    "    BisectingKMeans,\n",
    "    LDA  # Latent Dirichlet Allocation (토픽 모델링)\n",
    ")\n",
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator,\n",
    "    RegressionEvaluator,\n",
    "    ClusteringEvaluator\n",
    ")\n",
    "from pyspark.ml import Pipeline  # 전체 파이프라인 구성\n",
    "\n",
    "from pyspark.ml.tuning import (   # 모델 튜닝\n",
    "    ParamGridBuilder,\n",
    "    CrossValidator,\n",
    "    TrainValidationSplit\n",
    ")\n",
    "from pyspark.ml.linalg import Vectors, DenseVector, SparseVector  # 벡터 수동 생성\n",
    "from pyspark.ml.stat import Correlation, ChiSquareTest            # 통계 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c934e-c5e6-4a25-b470-a75d35aa664b",
   "metadata": {},
   "source": [
    "# 스파크 세션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cedc6af-3293-4a19-98e6-ae9f71810d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('classificationExample1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca07b4-6ec7-44b5-b238-de644dcbb245",
   "metadata": {},
   "source": [
    "# 타이타닉 데이터를 이용한 생존여부 예측모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bef3cc-2791-4a76-a7ed-e10d34b156f9",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a8def3-5539-4da5-bbea-2973a62a910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = spark.read.csv(\"learning_spark_data/titanic.csv\", header=True, inferSchema = True)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390d38aa-c262-4d26-adcf-0b73a41599e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Gender|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|     0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when, isnan\n",
    "\n",
    "# 결측치 처리\n",
    "null_counts = data.select(\n",
    "                    [\n",
    "                        sum( when(col(c).isNull() | isnan(c),1).otherwise(0) ).alias(c)\n",
    "                    for c in data.columns\n",
    "                    ]\n",
    "                )\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18e3b1d-fb79-4e51-87a3-1ae5f3dbfe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "data_1= data.select('Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare')\n",
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b062ab01-2d14-4d42-8f27-cfc912b2ce2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age 결측치 처리 - 평균값으로 대체\n",
    "mean_age = data_1.select('Age').agg( {\n",
    "    \"Age\" : \"mean\"\n",
    "}).collect()[0][0]\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f53d19-6349-4ed9-9804-8c74da0efd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|       0|     3|  male|             22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|             38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|             26.0|    0|    0|  7.925|\n",
      "|       1|     1|female|             35.0|    1|    0|   53.1|\n",
      "|       0|     3|  male|             35.0|    0|    0|   8.05|\n",
      "|       0|     3|  male|29.69911764705882|    0|    0| 8.4583|\n",
      "|       0|     1|  male|             54.0|    0|    0|51.8625|\n",
      "|       0|     3|  male|              2.0|    3|    1| 21.075|\n",
      "|       1|     3|female|             27.0|    0|    2|11.1333|\n",
      "|       1|     2|female|             14.0|    1|    0|30.0708|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1 = data_1.fillna( {\"Age\" : mean_age})\n",
    "data_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88eb7972-a35f-4373-9e1b-1990a6dce15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|SexIndexer|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       0.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       1.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       1.0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       1.0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       0.0|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 인코딩 StringIndexer\n",
    "indexer = StringIndexer( inputCol='Gender', outputCol='SexIndexer')\n",
    "data_1 = indexer.fit(data_1).transform(data_1)\n",
    "data_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6a9a90-24cc-493c-8460-7d0dd7ef3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,0.0,22.0,1.0...|       0|\n",
      "|[1.0,1.0,38.0,1.0...|       1|\n",
      "|[3.0,1.0,26.0,0.0...|       1|\n",
      "|[1.0,1.0,35.0,1.0...|       1|\n",
      "|[3.0,0.0,35.0,0.0...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FeatureVector 생성\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Pclass', 'SexIndexer', 'Age', 'SibSp', 'Parch','Fare' ],\n",
    "    outputCol='features'\n",
    ")\n",
    "data_1 = assembler.transform(data_1)\n",
    "data_1.select('features','Survived').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7e9e81-3fe7-4833-a03c-06a2483c748e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|  Fare|SexIndexer|            features|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|       0|     1|female| 2.0|    1|    2|151.55|       1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       0|     1|female|25.0|    1|    2|151.55|       1.0|[1.0,1.0,25.0,1.0...|\n",
      "|       0|     1|  male|18.0|    1|    0| 108.9|       0.0|[1.0,0.0,18.0,1.0...|\n",
      "|       0|     1|  male|19.0|    1|    0|  53.1|       0.0|[1.0,0.0,19.0,1.0...|\n",
      "|       0|     1|  male|19.0|    3|    2| 263.0|       0.0|[1.0,0.0,19.0,3.0...|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|SexIndexer|            features|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|       0|     1|female|             50.0|    0|    0|28.7125|       1.0|[1.0,1.0,50.0,0.0...|\n",
      "|       0|     1|  male|             21.0|    0|    1|77.2875|       0.0|[1.0,0.0,21.0,0.0...|\n",
      "|       0|     1|  male|             24.0|    0|    0|   79.2|       0.0|[1.0,0.0,24.0,0.0...|\n",
      "|       0|     1|  male|             29.0|    0|    0|   30.0|       0.0|[1.0,0.0,29.0,0.0...|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|  26.55|       0.0|[1.0,0.0,29.69911...|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋 분할\n",
    "train_data, test_data = data_1.randomSplit([0.8,0.2], seed=42)\n",
    "train_data.show(5), test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "505b4ff0-e235-4877-870a-6d2ad5675a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|[1.0,1.0,50.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,21.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,24.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.69911...|       0|       1.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'Survived')\n",
    "lr_model = lr.fit(train_data)\n",
    "predic = lr_model.transform(test_data)\n",
    "predic.select('features', 'Survived', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4252985-330d-4c9e-921e-26101b2cd3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "comp = predic.withColumn('correct', expr('case when Survived = prediction then 1 else 0 end'))\n",
    "comp.where('correct=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda65814-e997-415a-aa17-12ac9557d352",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|    Fare|SexIndexer|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|female|             50.0|    0|    0| 28.7125|       1.0|[1.0,1.0,50.0,0.0...|[-1.9520233772457...|[0.12433289705143...|       1.0|\n",
      "|       0|     1|  male|             21.0|    0|    1| 77.2875|       0.0|[1.0,0.0,21.0,0.0...|[-0.5063625084573...|[0.37604662481402...|       1.0|\n",
      "|       0|     1|  male|             24.0|    0|    0|    79.2|       0.0|[1.0,0.0,24.0,0.0...|[-0.5000095386390...|[0.37753842718518...|       1.0|\n",
      "|       0|     1|  male|             29.0|    0|    0|    30.0|       0.0|[1.0,0.0,29.0,0.0...|[-0.1615540822042...|[0.45969909487698...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|   26.55|       0.0|[1.0,0.0,29.69911...|[-0.1231782413911...|[0.46924431750958...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|    31.0|       0.0|[1.0,0.0,29.69911...|[-0.1347897264619...|[0.46635349453316...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|221.7792|       0.0|[1.0,0.0,29.69911...|[-0.6325941832296...|[0.34692254756630...|       1.0|\n",
      "|       0|     3|female|              9.0|    1|    1| 15.2458|       1.0|[3.0,1.0,9.0,1.0,...|[-0.8294985925619...|[0.30375110057917...|       1.0|\n",
      "|       0|     3|female|             14.0|    0|    0|  7.8542|       1.0|[3.0,1.0,14.0,0.0...|[-1.1048782816873...|[0.24882696769997...|       1.0|\n",
      "|       0|     3|female|             22.0|    0|    0| 10.5167|       1.0|[3.0,1.0,22.0,0.0...|[-0.7757027387564...|[0.31524678240576...|       1.0|\n",
      "|       0|     3|female|             28.0|    1|    1|    14.4|       1.0|[3.0,1.0,28.0,1.0...|[-0.0289998254718...|[0.49275055168429...|       1.0|\n",
      "|       0|     3|female|29.69911764705882|    0|    0|  8.1375|       1.0|[3.0,1.0,29.69911...|[-0.4460134544155...|[0.39030901997152...|       1.0|\n",
      "|       1|     1|  male|             40.0|    0|    0|    31.0|       0.0|[1.0,0.0,40.0,0.0...|[0.29800553338314...|[0.57395488063056...|       0.0|\n",
      "|       1|     1|  male|             42.0|    0|    0| 26.2875|       0.0|[1.0,0.0,42.0,0.0...|[0.39433268162065...|[0.59732526764030...|       0.0|\n",
      "|       1|     1|  male|             45.0|    0|    0|   26.55|       0.0|[1.0,0.0,45.0,0.0...|[0.51969380848810...|[0.62707616571001...|       0.0|\n",
      "|       1|     2|  male|              2.0|    1|    1|    26.0|       0.0|[2.0,0.0,2.0,1.0,...|[0.37184806510138...|[0.59190546052286...|       0.0|\n",
      "|       1|     3|female|29.69911764705882|    2|    0|   23.25|       1.0|[3.0,1.0,29.69911...|[0.29463470411987...|[0.57313040472105...|       0.0|\n",
      "|       1|     3|female|             33.0|    3|    0|   15.85|       1.0|[3.0,1.0,33.0,3.0...|[0.84267221664326...|[0.69902771706049...|       0.0|\n",
      "|       1|     3|female|             38.0|    1|    5| 31.3875|       1.0|[3.0,1.0,38.0,1.0...|[0.80563898861163...|[0.69117942146816...|       0.0|\n",
      "|       1|     3|female|             63.0|    0|    0|  9.5875|       1.0|[3.0,1.0,63.0,0.0...|[0.94935152197948...|[0.72098474515652...|       0.0|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 틀린 데이터만 필터링\n",
    "predic.filter( col('Survived') != col('prediction')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c20add0d-bf50-4879-ae41-ed29c3bb89ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068965517241379"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "comp.selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a84ce07-3273-48c3-957a-7a27e8b31de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664129586260734"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = BinaryClassificationEvaluator(labelCol='Survived',\n",
    "                                     rawPredictionCol='rawPrediction',\n",
    "                                     metricName='areaUnderROC')\n",
    "auc = eval.evaluate(predic)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c536c-9d3b-48c1-ac2e-78e302ddc93b",
   "metadata": {},
   "source": [
    "AUROC -> X축 FPR, y축 TPR 의 곡선 아래면적, 1에 가까울 수록 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfd9a1f-be54-452b-af91-1419aa44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1339ac7d-fc22-496a-ae64-8ba94c224c71",
   "metadata": {},
   "source": [
    "# libsvm 형식의 파일처리\n",
    "- 텍스트 파일 형식, 희소데이터용 압축파일이다. 메모리, 처리속도 개선 - 머신러닝에서 활용되는 형식\n",
    "- 레이블 행:값  행:값 -> 이런 형식의 데이터 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f094eca-6e9a-41c7-bf27-d783a6067e9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6c0a9c5a271b:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classificationExample2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fabf37b2b10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('classificationExample2').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b50bdc9-beb1-4c2f-96b8-a1e8b727a320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = spark.read.format('libsvm').load(\"learning_spark_data/sample_libsvm_data.txt\")\n",
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021245a9-0ada-43e9-8912-2b8aed99e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a291621-21eb-483f-8e46-15a49e3cb173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[95,96,97,12...|\n",
      "|  0.0|(692,[121,122,123...|\n",
      "|  0.0|(692,[122,123,124...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[98,99,100,1...|\n",
      "|  0.0|(692,[100,101,102...|\n",
      "|  0.0|(692,[123,124,125...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = data2.randomSplit([0.7,0.3], seed = 12)\n",
    "train_data.show(3), test_data.show(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d99fcce-0b4f-4d5d-958b-672bb90fa868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[0.95414441393043...|[0.72194788886091...|       0.0|\n",
      "|  0.0|(692,[100,101,102...|[0.48568919283978...|[0.61909039185191...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[1.00961478127974...|[0.73294475454830...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[0.90293696106823...|[0.71155267489794...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[0.75830339388632...|[0.68098526895593...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam = 0.8)\n",
    "lrModel = lr.fit(train_data)\n",
    "pred = lrModel.transform(test_data)\n",
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "052db011-ef9d-4a9f-b091-9c0042ea71ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "auc = eval.evaluate(pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d52a3fc-4618-444d-a41a-3276ae6d08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "231a5a63-8b87-4170-80ca-9a1a39d056bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6c0a9c5a271b:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>taxi-fare-prediction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fabf3c197d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('taxi-fare-prediction').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633f9a10-7db8-4fa0-b87d-b689ef4359cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/learning_spark_data/trips/*.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd =os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, 'learning_spark_data', 'trips', '*.csv' )\n",
    "trip_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6f2f515-0d4e-40ea-9843-d03750139b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"file:///{trip_data_path.replace(os.sep, '/')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bf0549d-384e-444e-9068-b2b18730ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "trip_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01011026-614a-4019-9dae-76d2577de41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    trip_distance,\n",
    "    total_amount\n",
    "FROM trips\n",
    "\n",
    "WHERE total_amount < 5000\n",
    "  AND total_amount > 0\n",
    "  AND trip_distance > 0\n",
    "  AND trip_distance < 500\n",
    "  AND passenger_count < 4\n",
    "  AND TO_DATE(tpep_pickup_datetime) >= \"2021-01-01\"\n",
    "  AND TO_DATE(tpep_pickup_datetime) < \"2021-08-01\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30c85e41-ee10-454b-b9fd-bbc048a7b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986582d-cf83-4490-b6e7-ab11b3047f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
