{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aae0f57-500c-4adb-8d0d-f5722cef767e",
   "metadata": {},
   "source": [
    "#06_SparkDataAnal.ipynb\n",
    "TLC Trip Record Data\n",
    "출처: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f9dbf9-77ee-477b-853d-d45ed544e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aed4298-418f-4e9f-8ace-f2acbe6f4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = spark.read.format('json')\\\n",
    "    .load('learning_spark_data/2015-summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777c2c32-4e07-4a21-b395-9e3e96d08a5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0804289-68fd-4a6c-89f0-05a95ce1f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3504c6-bc95-4be8-99fc-f2e78f8cfe8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54bec20-d358-476f-a14e-2216e537682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|   15|\n",
      "|    1|\n",
      "|  344|\n",
      "|   15|\n",
      "|   62|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5b406a7-3e7d-4587-8a7a-de8e4fb20b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 도착국가명 중복제거\n",
    "df.select('DEST_COUNTRY_NAME').distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8c2d3d-defd-47b5-a8f2-17461f896bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.select('DEST_COUNTRY_NAME').distinct().cache()\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1da1aae-2cc2-4c29-a448-cf1f7542e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row('hello', None, 1, False)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row class 를 이용한 단일 레코드 생성\n",
    "from pyspark.sql import Row\n",
    "myRow = Row(\"hello\", None, 1, False)\n",
    "myRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2334d024-37a6-4a7d-b0f4-a78233b0a9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, withinCountry: boolean]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 컬럼 추가하기\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df3 = df.withColumn('withinCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME')) # epxr sql표현식을 받아 생성\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f767f457-35e8-478e-8553-0a3910d7a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "|    United States|            Ireland|  344|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a90968-4d42-45d4-b4ec-bf908224a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|withinCountry|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "|    United States|      United States|370002|         true|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.filter(df3['withinCountry'] == True).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ba3df5-95ce-40c7-afc0-0e59c5962528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|withinCountry|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "|    United States|      United States|370002|         true|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.createOrReplaceTempView(\"df3_view\")\n",
    "\n",
    "query = '''\n",
    "SELECT *\n",
    "FROM df3_view\n",
    "WHERE withinCountry = True\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a008f21-8068-4a16-8478-c9479f589427",
   "metadata": {},
   "source": [
    "# 강사님 버전\n",
    "df4 = df.withColumn('Category', expr(\"CASE WHEN count<10 THEN 'under' WHEN count>=10 THEN 'upper' END\"))\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac097a2c-f460-41cd-a2d4-5ebd81a59d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case when 카운트 10 이하 under, 이상 upper로 변환 > category 컬럼 추가\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df3 = df3.withColumn(\n",
    "    \"category\",\n",
    "    when(df3[\"count\"] <= 10, \"under\").otherwise(\"upper\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72a9946b-a29f-413a-84c3-b4937b96970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|category|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|    United States|            Romania|   15|        false|   upper|\n",
      "|    United States|            Croatia|    1|        false|   under|\n",
      "|    United States|            Ireland|  344|        false|   upper|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01becb4a-fb1f-46ff-807e-c43cc46748f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|category|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|    United States|            Romania|   15|        false|   upper|\n",
      "|    United States|            Croatia|    1|        false|   under|\n",
      "|    United States|            Ireland|  344|        false|   upper|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT *,\n",
    "       CASE \n",
    "           WHEN count <= 10 THEN 'under'\n",
    "           ELSE 'upper'\n",
    "       END AS category\n",
    "FROM df3_view\n",
    "'''\n",
    "spark.sql(query).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd6ac879-ad17-4368-9bb2-003a04f77619",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a61c6822-e75c-46ec-bf84-688b15f1ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"emp\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62de68e9-11c2-4816-a1dc-f09bb83959d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df = spark.read.format('csv')\\\n",
    "    .option('header', 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('learning_spark_data/dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "349a31b4-fe77-4b46-9cbc-74d6b534df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.read.format('csv')\\\n",
    "    .option('header', 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('learning_spark_data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "716c3b23-6cbc-4fe1-8db8-f1a97a62912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select('*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13957793-e89b-4067-acb4-d790582746b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.selectExpr('count(*)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ed91c30-99e7-4f93-954e-aa1b31e6ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "emp_df.select( countDistinct('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8be912f8-7712-47ef-a175-36a6c4ed2189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "emp_df.select( approx_count_distinct('job', 0.1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a88c6a1-e164-4cda-8664-c6cb031eb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, last, min, max, sum, avg -> (expr: sql문장 x) function으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04e0fdb5-c1df-451e-8f2c-57c379763e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first, last, min, max, sum, avg, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "963a942b-9a45-4b09-8b1c-70059f20eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(sal)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(count('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab1f718b-5346-4094-90c7-555a8a04eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|first(sal)|\n",
      "+----------+\n",
      "|       800|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(first('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f0eb82d-d198-4e9c-9c95-a887bddf017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(sal)|\n",
      "+--------+\n",
      "|    5000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(max('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de431856-d706-47b0-b19e-63f6480c52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38c2f9e8-24b6-465e-9a00-4fc676585247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|total_transaction|\n",
      "+-----------------+\n",
      "|               15|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(expr('count (sal) as total_transaction')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15733e69-2119-4228-b5de-6910a19763ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-----------+\n",
      "|total_transaction|avg_salary|mean_salary|\n",
      "+-----------------+----------+-----------+\n",
      "|               15|   2148.33|    2148.33|\n",
      "+-----------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#total_salary / total_transaction, avg_salary, mean_salary\n",
    "emp_df.selectExpr(\n",
    "    \"count(sal) as total_transaction\",\n",
    "    \"round(avg(sal),2) as avg_salary\",\n",
    "    \"round(mean(sal),2) as mean_salary\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa87fea7-842e-40ad-8768-29444e6db116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그룹화\n",
    "emp_df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2f5bbdc-d755-4265-84d5-48818201eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+--------+\n",
      "|      job|qty|count(job)|sum(sal)|\n",
      "+---------+---+----------+--------+\n",
      "|  ANALYST|  2|         2|    6000|\n",
      "| SALESMAN|  4|         4|    5600|\n",
      "|    CLERK|  5|         5|    7350|\n",
      "|  MANAGER|  3|         3|    8275|\n",
      "|PRESIDENT|  1|         1|    5000|\n",
      "+---------+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy('job').agg(\n",
    "    count('job').alias('qty'),\n",
    "    expr('count(job)'),\n",
    "         sum('sal')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a74f86e3-d1d5-4049-9ac0-e2680e709d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+\n",
      "|      job|SAL_AVG|SAL_STDEV|\n",
      "+---------+-------+---------+\n",
      "|  ANALYST| 3000.0|      0.0|\n",
      "| SALESMAN| 1400.0|   177.95|\n",
      "|    CLERK| 1470.0|   984.63|\n",
      "|  MANAGER|2758.33|   274.24|\n",
      "|PRESIDENT| 5000.0|     NULL|\n",
      "+---------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sal의 평균(SAL_AVG), 표준편차(SAL_STDEV)를 job별로 계산해서 출력,소수점 두자리\n",
    "emp_df.groupBy('job').agg(\n",
    "    expr('round(avg(sal),2) as SAL_AVG') ,\n",
    "    expr('round(stddev(sal),2) as SAL_STDEV')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b30d799a-08b5-4487-b993-f9d73b6d8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rank, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "04c07399-f39d-451a-9efb-568b91e725eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 급여 top 10 보내기\n",
    "from pyspark.sql.window import Window\n",
    "windowspec = Window.orderBy(desc('sal'))\n",
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eaef0985-1a36-4ada-a812-fc9172613e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+----+----------+----+----+------+\n",
      "|empno| ename|     job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+--------+----+----------+----+----+------+\n",
      "| 7369| SMITH|   CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7499| ALLEN|SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD|SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES| MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7654|MARTIN|SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "+-----+------+--------+----+----------+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da5a67ba-7cdf-45d8-b57e-1ddcdf212b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+----+----------+----+----+------+-----------+\n",
      "|empno|ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+-----+---------+----+----------+----+----+------+-----------+\n",
      "| 7839| KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|          1|\n",
      "| 9292| JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|          2|\n",
      "| 7788|SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|          3|\n",
      "| 7902| FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|          3|\n",
      "| 7566|JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|          5|\n",
      "+-----+-----+---------+----+----------+----+----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn('salary_rank', salAllRank).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7278524b-5212-470d-b449-6a6c8493c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+----+----------+----+----+------+----+\n",
      "|empno|ename|    job| mgr|  hiredate| sal|comm|deptno|rank|\n",
      "+-----+-----+-------+----+----------+----+----+------+----+\n",
      "| 7788|SCOTT|ANALYST|7566|1987-04-19|3000|NULL|    20|   1|\n",
      "| 7902| FORD|ANALYST|7566|1981-12-03|3000|NULL|    20|   1|\n",
      "| 9292| JACK|  CLERK|7782|1982-01-23|3200|NULL|    70|   1|\n",
      "+-----+-----+-------+----+----------+----+----+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 직무별로 급여 내림차순 정렬 기준의 윈도우 정의\n",
    "windowSpec = Window.partitionBy(\"job\").orderBy(desc(\"sal\"))\n",
    "\n",
    "# 2. rank() 함수 적용하여 직무별 순위 매기기\n",
    "job_rank_df = emp_df.withColumn(\"rank\", rank().over(windowSpec))\n",
    "\n",
    "# 3. 결과 확인\n",
    "job_rank_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "406022ff-b393-4242-a236-29809b7f09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----------+\n",
      "|      job|sumsal|salary_rank|\n",
      "+---------+------+-----------+\n",
      "|  MANAGER|  8275|          1|\n",
      "|    CLERK|  7350|          2|\n",
      "|  ANALYST|  6000|          3|\n",
      "| SALESMAN|  5600|          4|\n",
      "|PRESIDENT|  5000|          5|\n",
      "+---------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndf = emp_df.groupBy('job').agg(expr('sum(sal) as sumsal'))\n",
    "windowspec = Window.orderBy(desc('sumsal'))\n",
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank\n",
    "ndf.withColumn('salary_rank', salAllRank).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e018d3b-f571-4a34-aad0-ca69f973d569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
