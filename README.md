# âš¡ WhyNot 7ê¸° ì†Œí”„íŠ¸ì›¨ì–´ ìº í”„ - PySpark ì‹¤ìŠµ í¬íŠ¸í´ë¦¬ì˜¤

ì´ ì €ì¥ì†ŒëŠ” WhyNot 7ê¸° ì†Œí”„íŠ¸ì›¨ì–´ ìº í”„ì—ì„œ ìˆ˜í–‰í•œ PySpark ì‹¤ìŠµ ë° í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ì„ ì •ë¦¬í•œ í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.  
RDDë¶€í„° DataFrame, SQL, ë¨¸ì‹ ëŸ¬ë‹ê¹Œì§€ ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ì˜ íë¦„ì„ ì‹¤ìŠµ ìœ„ì£¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ PySpark ì‹¤ìŠµ íŒŒì¼ ì •ë¦¬

| ë²ˆí˜¸ | íŒŒì¼ëª…                           | ì£¼ì œ ìš”ì•½                             |
|------|----------------------------------|----------------------------------------|
| 00   | `00_hello_pyspark.ipynb`         | PySpark í™˜ê²½ ì„¤ì • ë° Hello World í…ŒìŠ¤íŠ¸ |
| 01   | `01_start_spark.ipynb`           | SparkSession ìƒì„± ë° ê¸°ë³¸ êµ¬ì¡° ì´í•´      |
| 02   | `02_RDD_test.ipynb`              | RDD ê¸°ì´ˆ ì‹¤ìŠµ (ìƒì„±, map, reduce ë“±)     |
| 02-1 | `02_mnm_result_load.py`          | MNM ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° RDD í™œìš© ì‹¤ìŠµ     |
| 03   | `03_KVRDD.ipynb`                 | (key, value) êµ¬ì¡° ê¸°ë°˜ RDD ì—°ì‚° ì‹¤ìŠµ     |
| 04   | `04_Operations.ipynb`            | Transformation & Action ì¢…í•© ì‹¤ìŠµ       |
| 05   | `05_SparkSQL_DF.ipynb`           | DataFrameê³¼ SQL í™œìš©                    |
| 06   | `06_SparkDataAnal.ipynb`         | DataFrame ê¸°ë°˜ EDA ë° ì •ì œ              |
| 07   | `07_Classification.ipynb`        | ë¶„ë¥˜ ëª¨ë¸ (Logistic Regression ë“±) ì‹¤ìŠµ |
| 08-1 | `08_01_Regression_1.ipynb`       | íšŒê·€ëª¨ë¸ (ë‹¨ìˆœì„ í˜•íšŒê·€) ì‹¤ìŠµ            |
| 08-2 | `08_02_Regression.ipynb`         | íšŒê·€ëª¨ë¸ (ë‹¤ì¤‘íšŒê·€, ì„±ëŠ¥ í‰ê°€ ë“±) ì‹¤ìŠµ  |
> ê° ì‹¤ìŠµì€ ì£¼ì œë³„ë¡œ ì •ë¦¬ë˜ì–´ ìˆìœ¼ë©°, ì½”ë“œì™€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ›  ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ

- **PySpark 3.5+**
  ![Spark](https://img.shields.io/badge/PySpark-EE7C15?logo=apachespark&logoColor=white)
- **Python 3.12** ![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
- **Jupyter Notebook** ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?logo=jupyter&logoColor=white)
- **Docker** ![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
- **XShell** ![Xshell](https://img.shields.io/badge/Xshell-DC1F29?logo=gnu-bash&logoColor=white)
- **VMware**  ![VMware](https://img.shields.io/badge/VMware-607078?logo=vmware&logoColor=white)
- **Ubuntu 22.04** ![Ubuntu](https://img.shields.io/badge/Ubuntu-E95420?logo=ubuntu&logoColor=white)

---

## ğŸš€ ì˜ˆì‹œ í”„ë¡œì íŠ¸: NYC FHV ìŠ¹í•˜ì°¨ ë¶„ì„

**ì„¤ëª…:**  
`fhvhv_tripdata_2020-03.csv`ì™€ `taxi_zone_lookup.csv`ë¥¼ í™œìš©í•´ NYC ë‚´ FHV ì„œë¹„ìŠ¤ì˜ ìŠ¹í•˜ì°¨ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.

### ğŸ“Œ ì£¼ìš” ë¶„ì„
- ì„œë¹„ìŠ¤ì¡´ë³„ ìŠ¹ì°¨/í•˜ì°¨ ê±´ìˆ˜ ì§‘ê³„
- `Manhattan` ì§€ì—­ì˜ ì£¼ìš” í•˜ì°¨ ì§€ì  í•„í„°ë§
- PySpark SQL â†” DataFrame API ë³€í™˜ ì‹¤ìŠµ

### ğŸ” ì£¼ìš” ì½”ë“œ ì˜ˆì‹œ

```python
pickup_df = trip_df.join(zone_df, trip_df.PULocationID == zone_df.LocationID) \
    .groupBy("Zone").agg(count("*").alias("pickup_count"))

dropoff_df = trip_df.join(zone_df, trip_df.DOLocationID == zone_df.LocationID) \
    .groupBy("Zone").agg(count("*").alias("dropoff_count"))

summary_df = pickup_df.join(dropoff_df, "Zone", "outer").na.fill(0)


